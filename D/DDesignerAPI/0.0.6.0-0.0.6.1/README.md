# Comparing `tmp/DDesignerAPI-0.0.6.0-py3-none-any.whl.zip` & `tmp/DDesignerAPI-0.0.6.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 66111 bytes, number of entries: 31
+Zip file size: 67999 bytes, number of entries: 31
 -rw-rw-r--  2.0 unx     1920 b- defN 23-Jul-25 06:20 ddesigner_api/__init__.py
 -rw-rw-r--  2.0 unx     1683 b- defN 23-Jul-25 06:20 ddesigner_api/numpy/__init__.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 06:20 ddesigner_api/numpy/examples/__init__.py
 -rw-rw-r--  2.0 unx     3541 b- defN 23-Jul-25 06:20 ddesigner_api/numpy/examples/examples_numpy.py
 -rw-rw-r--  2.0 unx     1742 b- defN 23-Aug-29 07:13 ddesigner_api/numpy/xwn/__init__.py
 -rw-rw-r--  2.0 unx     5457 b- defN 23-Nov-22 07:59 ddesigner_api/numpy/xwn/functions.py
 -rw-rw-r--  2.0 unx     5736 b- defN 23-Aug-29 06:13 ddesigner_api/numpy/xwn/optimization.py
@@ -10,24 +10,24 @@
 -rw-rw-r--  2.0 unx     6579 b- defN 23-Aug-24 12:09 ddesigner_api/pytorch/dpi_nn.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 06:20 ddesigner_api/pytorch/examples/__init__.py
 -rw-rw-r--  2.0 unx    13958 b- defN 23-Aug-09 06:25 ddesigner_api/pytorch/examples/examples_pytorch.py
 -rw-rw-r--  2.0 unx     1694 b- defN 23-Jul-25 06:20 ddesigner_api/pytorch/xwn/__init__.py
 -rw-rw-r--  2.0 unx    56563 b- defN 23-Aug-24 12:09 ddesigner_api/pytorch/xwn/torch_nn.py
 -rw-rw-r--  2.0 unx     6317 b- defN 23-Aug-25 03:50 ddesigner_api/pytorch/xwn/torch_opt.py
 -rw-rw-r--  2.0 unx      873 b- defN 23-Jul-25 06:20 ddesigner_api/tensorflow/__init__.py
--rw-rw-r--  2.0 unx    20578 b- defN 23-Dec-26 09:16 ddesigner_api/tensorflow/dpi_blocks.py
+-rw-rw-r--  2.0 unx    25752 b- defN 24-May-09 13:38 ddesigner_api/tensorflow/dpi_blocks.py
 -rw-rw-r--  2.0 unx    26909 b- defN 23-Dec-26 09:15 ddesigner_api/tensorflow/dpi_layers.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jul-25 06:20 ddesigner_api/tensorflow/examples/__init__.py
 -rw-rw-r--  2.0 unx     7883 b- defN 23-Jul-25 06:20 ddesigner_api/tensorflow/examples/examples_keras.py
 -rw-rw-r--  2.0 unx     3021 b- defN 23-Jul-25 06:20 ddesigner_api/tensorflow/examples/examples_tensorflow.py
 -rw-rw-r--  2.0 unx      841 b- defN 23-Nov-17 07:54 ddesigner_api/tensorflow/xwn/__init__.py
 -rw-rw-r--  2.0 unx    16764 b- defN 23-Aug-16 15:18 ddesigner_api/tensorflow/xwn/base_conv.py
--rw-rw-r--  2.0 unx    29614 b- defN 23-Aug-16 03:38 ddesigner_api/tensorflow/xwn/keras_layers.py
+-rw-rw-r--  2.0 unx    39707 b- defN 24-May-09 13:45 ddesigner_api/tensorflow/xwn/keras_layers.py
 -rw-rw-r--  2.0 unx     8393 b- defN 23-Nov-18 00:01 ddesigner_api/tensorflow/xwn/keras_opt.py
 -rw-rw-r--  2.0 unx     9240 b- defN 23-Jul-25 06:20 ddesigner_api/tensorflow/xwn/tf_nn.py
 -rw-rw-r--  2.0 unx     4167 b- defN 23-Jul-25 06:20 ddesigner_api/tensorflow/xwn/tf_opt.py
--rwxrwxr-x  2.0 unx    22114 b- defN 23-Dec-26 09:22 DDesignerAPI-0.0.6.0.dist-info/LICENSE
--rw-rw-r--  2.0 unx     7892 b- defN 23-Dec-26 09:22 DDesignerAPI-0.0.6.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Dec-26 09:22 DDesignerAPI-0.0.6.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       14 b- defN 23-Dec-26 09:22 DDesignerAPI-0.0.6.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2924 b- defN 23-Dec-26 09:22 DDesignerAPI-0.0.6.0.dist-info/RECORD
-31 files, 268279 bytes uncompressed, 61295 bytes compressed:  77.2%
+-rwxrwxr-x  2.0 unx    22114 b- defN 24-May-11 01:11 DDesignerAPI-0.0.6.1.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     7888 b- defN 24-May-11 01:11 DDesignerAPI-0.0.6.1.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-May-11 01:11 DDesignerAPI-0.0.6.1.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       14 b- defN 24-May-11 01:11 DDesignerAPI-0.0.6.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2924 b- defN 24-May-11 01:11 DDesignerAPI-0.0.6.1.dist-info/RECORD
+31 files, 283542 bytes uncompressed, 63183 bytes compressed:  77.7%
```

## zipnote {}

```diff
@@ -72,23 +72,23 @@
 
 Filename: ddesigner_api/tensorflow/xwn/tf_nn.py
 Comment: 
 
 Filename: ddesigner_api/tensorflow/xwn/tf_opt.py
 Comment: 
 
-Filename: DDesignerAPI-0.0.6.0.dist-info/LICENSE
+Filename: DDesignerAPI-0.0.6.1.dist-info/LICENSE
 Comment: 
 
-Filename: DDesignerAPI-0.0.6.0.dist-info/METADATA
+Filename: DDesignerAPI-0.0.6.1.dist-info/METADATA
 Comment: 
 
-Filename: DDesignerAPI-0.0.6.0.dist-info/WHEEL
+Filename: DDesignerAPI-0.0.6.1.dist-info/WHEEL
 Comment: 
 
-Filename: DDesignerAPI-0.0.6.0.dist-info/top_level.txt
+Filename: DDesignerAPI-0.0.6.1.dist-info/top_level.txt
 Comment: 
 
-Filename: DDesignerAPI-0.0.6.0.dist-info/RECORD
+Filename: DDesignerAPI-0.0.6.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ddesigner_api/tensorflow/dpi_blocks.py

```diff
@@ -255,14 +255,127 @@
             if l is not None:
                 x = l(x)
 
         return x
 
 
 @tf.keras.utils.register_keras_serializable()
+class DWConv2DBlock(layers.Layer):
+
+    def __init__(
+        self,
+        kernel_size,
+        strides=(1,1),
+        padding='valid',
+        depth_multiplier=1,
+        data_format=None,
+        dilation_rate=(1,1),
+        activation=None,
+        use_bias=False,
+        depthwise_initializer='glorot_uniform',
+        bias_initializer='zeros',
+        depthwise_regularizer=None,
+        bias_regularizer=None,
+        activity_regularizer=None,
+        depthwise_constraint=None,
+        bias_constraint=None,
+        dtype='float32',
+        # Components
+        convolution=None,
+        batchnormalization=None,
+        dropout=None,
+        # Optimization
+        transform=None,
+        pruning=None,
+        max_scale=4.0,
+        order=['CONV', 'BN', 'ACT', 'DROPOUT'],
+        **kwargs
+    ):
+        kwargs["dtype"] = "float16" if dtype == "mixed_float16" else dtype
+        super(DWConv2DBlock, self).__init__(**kwargs)
+        kwargs["dtype"] = dtype
+
+        # Assign
+        self.bn = batchnormalization
+        self.act = activation
+        self.dropout = dropout
+
+        self.kernel_size = kernel_size
+        self.transform = transform
+        self.pruning = pruning
+        self.max_scale = max_scale
+
+        self.use_transform = True if transform is not None else False
+        self.bit = transform if transform is not None else 4
+        self.use_pruning = True if pruning is not None else False
+        self.prun_weight = pruning if pruning is not None else 0.5
+        self.transpose = False
+
+        # Conv
+        if convolution is None:
+            self.conv = klayers.DepthwiseConv2D(
+                kernel_size,
+                strides=strides,
+                padding=padding,
+                depth_multiplier=depth_multiplier,
+                data_format=data_format,
+                dilation_rate=dilation_rate,
+                use_bias=use_bias,
+                depthwise_initializer=depthwise_initializer,
+                bias_initializer=bias_initializer,
+                depthwise_regularizer=depthwise_regularizer,
+                bias_regularizer=bias_regularizer,
+                activity_regularizer=activity_regularizer,
+                depthwise_constraint=depthwise_constraint,
+                bias_constraint=bias_constraint,
+                # dtype=dtype,
+
+                use_transform=self.use_transform,
+                bit=self.bit,
+                max_scale=self.max_scale,
+                use_pruning=self.use_pruning,
+                prun_weight=self.prun_weight,
+                **kwargs,
+            )
+        else:
+            self.conv = convolution
+
+        self.layer_list = []
+        for o in order:
+            if o == 'CONV': self.layer_list.append(self.conv)
+            elif o == 'BN': self.layer_list.append(self.bn)
+            elif o == 'ACT': self.layer_list.append(self.act)
+            elif o == 'DROPOUT': self.layer_list.append(self.dropout)
+
+    def get_config(self):
+        config = {
+            'kernel_size' : self.kernel_size,
+            'transform' : self.transform,
+            'max_scale' : self.max_scale,
+            'pruning' : self.pruning,
+            'convolution' : self.conv,
+            'batchnormalization' : self.bn,
+            'activation' : self.act,
+            'dropout' : self.dropout,
+            'dtype' : self.dtype,
+        }
+        base_config = super(DWConv2DBlock, self).get_config()
+        base_config.update(config)
+        return base_config
+
+    def call(self, inputs, training=None):
+        x = inputs
+        for l in self.layer_list:
+            if l is not None:
+                x = l(x)
+
+        return x
+
+
+@tf.keras.utils.register_keras_serializable()
 class FCBlock(layers.Layer):
 
     def __init__(
         self, 
         units,
         activation=None,
         use_bias=True,
@@ -584,56 +697,74 @@
 @tf.keras.utils.register_keras_serializable()
 class PositionEncoder(layers.Layer):
     def __init__(
         self,
         projection=None,
         height=7,
         width=7,
+        batch_size=32,
         num_channels=3,
         dtype="float32",
         **kwargs,
     ):
         kwargs["dtype"] = "float16" if dtype == "mixed_float16" else dtype
         super(PositionEncoder, self).__init__(**kwargs)
         kwargs["dtype"] = dtype
 
         self.projection = projection
         self.num_channels = num_channels
+        self.b = batch_size
         self.w = width
         self.h = height
+        self.rw = width + 1 if width % 2 != 0 else width
+        self.rh = height + 1 if height % 2 != 0 else height
+
+        self.n_half = int(num_channels / 2)
+        self.div_term = tf.exp(tf.range(0, self.num_channels, delta=2, dtype=tf.float32) * -(tf.math.log(10000.0) / float(self.num_channels)))
 
         self.regularizer_rate = 5e-4
 
     def build(self, input_shape):
         (_, _, _, self.e) = input_shape
 
-        # Create the positional embedding layer.
-        self.position_embedding = layers.Embedding(
-            input_dim=self.h * self.w, 
-            output_dim=self.e,
-            dtype=self.dtype
-        ) # (self.h * self.w, self.e) 
-
     def get_config(self):
         config = {
             'projection' : self.projection,
             'num_channels' : self.num_channels,
             'height' : self.h,
             'width' : self.w,
             'dtype' : self.dtype,
+            'batch_size' : self.b,
         }
         base_config = super(PositionEncoder, self).get_config()
         base_config.update(config)
         return base_config
 
     def call(self, x):
         # Get the positional embeddings.
-        positions = tf.range(start=0, limit=self.h * self.w, delta=1)
-        pos_embeddings = self.position_embedding(positions[None, ...])
+        sin_ry = tf.range(0, self.rh, delta=2, dtype=tf.float32)
+        cos_ry = tf.range(1, self.rh, delta=2, dtype=tf.float32)
+        sin_rx = tf.range(0, self.rw, delta=2, dtype=tf.float32)
+        cos_rx = tf.range(1, self.rw, delta=2, dtype=tf.float32)
+
+        sin_rx = tf.math.sin(sin_rx[:, None] * self.div_term[None, :])[..., None]   # (W/2,C/2,1)
+        cos_rx = tf.math.cos(cos_rx[:, None] * self.div_term[None, :])[..., None]   # (W/2,C/2,1)
+        rx = tf.concat([sin_rx, cos_rx], axis=-1)                                   # (W/2,C/2,2)
+        rx = tf.reshape(rx, (1, self.rw, self.n_half))[:, :self.w, :]               # (1,W,C/2)
+        rx = tf.tile(rx, (self.h, 1, 1))                                            # (H,W,C/2)
+
+        sin_ry = tf.math.sin(sin_ry[:, None] * self.div_term[None, :])[..., None]   # (H/2,C/2,1)
+        cos_ry = tf.math.cos(cos_ry[:, None] * self.div_term[None, :])[..., None]   # (H/2,C/2,1)
+        ry = tf.concat([sin_ry, cos_ry], axis=-1)                                   # (H/2,C/2,2)
+        ry = tf.reshape(ry, (self.rh, 1, self.n_half))[:self.h, ...]                # (H,1,C/2)
+        ry = tf.tile(ry, (1, self.w, 1))                                            # (H,W,C/2)
+
+        pos_embeddings = tf.reshape(tf.concat([rx, ry], axis=-1), (1, self.h, self.w, self.num_channels))   # (1,H,W,C)
+        pos_embeddings = tf.cast(tf.tile(pos_embeddings, (self.b, 1, 1, 1)), self.dtype)                    # (B,H,W,C)
 
         # Embed the patches.
-        # x = x + tf.reshape(pos_embeddings, (self.h, self.w, self.e))[None, ...]
-        x = tf.concat(
-            [x, tf.broadcast_to(tf.reshape(pos_embeddings, (self.h, self.w, self.e))[None, ...], tf.shape(x))], axis=-1)
+        x = x + pos_embeddings
         if self.projection is not None:
             x = self.projection(x)
         return x
+                                                                                                                                                                                          725,16        Bot
+
```

## ddesigner_api/tensorflow/xwn/keras_layers.py

```diff
@@ -346,14 +346,270 @@
             bit=bit, 
             max_scale=max_scale,
             prun_weight=prun_weight,
             **kwargs
         )
 
 @tf.keras.utils.register_keras_serializable()
+class DepthwiseConv2D(Conv2D):
+  """Depthwise 2D convolution.
+
+  Depthwise convolution is a type of convolution in which a single convolutional
+  filter is apply to each input channel (i.e. in a depthwise way).
+  You can understand depthwise convolution as being
+  the first step in a depthwise separable convolution.
+
+  It is implemented via the following steps:
+
+  - Split the input into individual channels.
+  - Convolve each input with the layer's kernel (called a depthwise kernel).
+  - Stack the convolved outputs together (along the channels axis).
+
+  Unlike a regular 2D convolution, depthwise convolution does not mix
+  information across different input channels.
+
+  The `depth_multiplier` argument controls how many
+  output channels are generated per input channel in the depthwise step.
+
+ Args:
+    kernel_size: An integer or tuple/list of 2 integers, specifying the
+      height and width of the 2D convolution window.
+      Can be a single integer to specify the same value for
+      all spatial dimensions.
+    strides: An integer or tuple/list of 2 integers,
+      specifying the strides of the convolution along the height and width.
+      Can be a single integer to specify the same value for
+      all spatial dimensions.
+      Specifying any stride value != 1 is incompatible with specifying
+      any `dilation_rate` value != 1.
+    padding: one of `'valid'` or `'same'` (case-insensitive).
+      `"valid"` means no padding. `"same"` results in padding with zeros evenly
+      to the left/right or up/down of the input such that output has the same
+      height/width dimension as the input.
+    depth_multiplier: The number of depthwise convolution output channels
+      for each input channel.
+      The total number of depthwise convolution output
+      channels will be equal to `filters_in * depth_multiplier`.
+    data_format: A string,
+      one of `channels_last` (default) or `channels_first`.
+      The ordering of the dimensions in the inputs.
+      `channels_last` corresponds to inputs with shape
+      `(batch_size, height, width, channels)` while `channels_first`
+      corresponds to inputs with shape
+      `(batch_size, channels, height, width)`.
+      It defaults to the `image_data_format` value found in your
+      Keras config file at `~/.keras/keras.json`.
+      If you never set it, then it will be 'channels_last'.
+    dilation_rate: An integer or tuple/list of 2 integers, specifying
+      the dilation rate to use for dilated convolution.
+      Currently, specifying any `dilation_rate` value != 1 is
+      incompatible with specifying any `strides` value != 1.
+    activation: Activation function to use.
+      If you don't specify anything, no activation is applied (
+      see `keras.activations`).
+    use_bias: Boolean, whether the layer uses a bias vector.
+    depthwise_initializer: Initializer for the depthwise kernel matrix (
+      see `keras.initializers`). If None, the default initializer (
+      'glorot_uniform') will be used.
+    bias_initializer: Initializer for the bias vector (
+      see `keras.initializers`). If None, the default initializer (
+      'zeros') will bs used.
+    depthwise_regularizer: Regularizer function applied to
+      the depthwise kernel matrix (see `keras.regularizers`).
+    bias_regularizer: Regularizer function applied to the bias vector (
+      see `keras.regularizers`).
+    activity_regularizer: Regularizer function applied to
+      the output of the layer (its 'activation') (
+      see `keras.regularizers`).
+    depthwise_constraint: Constraint function applied to
+      the depthwise kernel matrix (
+      see `keras.constraints`).
+    bias_constraint: Constraint function applied to the bias vector (
+      see `keras.constraints`).
+
+  Input shape:
+    4D tensor with shape:
+    `[batch_size, channels, rows, cols]` if data_format='channels_first'
+    or 4D tensor with shape:
+    `[batch_size, rows, cols, channels]` if data_format='channels_last'.
+
+  Output shape:
+    4D tensor with shape:
+    `[batch_size, channels * depth_multiplier, new_rows, new_cols]` if
+    data_format='channels_first' or 4D tensor with shape:
+    `[batch_size, new_rows, new_cols, channels * depth_multiplier]` if
+    data_format='channels_last'. `rows` and `cols` values might have
+    changed due to padding.
+
+  Returns:
+    A tensor of rank 4 representing
+    `activation(depthwiseconv2d(inputs, kernel) + bias)`.
+
+  Raises:
+    ValueError: if `padding` is "causal".
+    ValueError: when both `strides` > 1 and `dilation_rate` > 1.
+  """
+
+  def __init__(self,
+        kernel_size,
+        strides=(1, 1),
+        padding='valid',
+        depth_multiplier=1,
+        data_format=None,
+        dilation_rate=(1, 1),
+        activation=None,
+        use_bias=True,
+        depthwise_initializer='glorot_uniform',
+        bias_initializer='zeros',
+        depthwise_regularizer=None,
+        bias_regularizer=None,
+        activity_regularizer=None,
+        depthwise_constraint=None,
+        bias_constraint=None,
+
+        dtype='float32',
+        use_transform=False,
+        use_pruning=False,
+        bit=4,
+        max_scale=4.0,
+        prun_weight=0.5,
+
+        **kwargs
+    ):
+    super(DepthwiseConv2D, self).__init__(
+        filters=None,
+        kernel_size=kernel_size,
+        strides=strides,
+        padding=padding,
+        data_format=data_format,
+        dilation_rate=dilation_rate,
+        activation=activation,
+        use_bias=use_bias,
+        bias_regularizer=bias_regularizer,
+        activity_regularizer=activity_regularizer,
+        bias_constraint=bias_constraint,
+        **kwargs)
+    self.depth_multiplier = depth_multiplier
+    self.depthwise_initializer = initializers.get(depthwise_initializer)
+    self.depthwise_regularizer = regularizers.get(depthwise_regularizer)
+    self.depthwise_constraint = constraints.get(depthwise_constraint)
+    self.bias_initializer = initializers.get(bias_initializer)
+
+    # Add optimization kernel
+    self.opt = Optimization(
+        use_transform=use_transform,
+        bit=bit,
+        max_scale=max_scale,
+        use_pruning=use_pruning,
+        prun_weight=prun_weight,
+        dtype=dtype,
+        transpose=False,
+    )
+
+  def build(self, input_shape):
+    if len(input_shape) < 4:
+      raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '
+                       'Received input shape:', str(input_shape))
+    input_shape = tensor_shape.TensorShape(input_shape)
+    channel_axis = self._get_channel_axis()
+    if input_shape.dims[channel_axis].value is None:
+      raise ValueError('The channel dimension of the inputs to '
+                       '`DepthwiseConv2D` '
+                       'should be defined. Found `None`.')
+    input_dim = int(input_shape[channel_axis])
+    depthwise_kernel_shape = (self.kernel_size[0],
+                              self.kernel_size[1],
+                              input_dim,
+                              self.depth_multiplier)
+
+    self.depthwise_kernel = self.add_weight(
+        shape=depthwise_kernel_shape,
+        initializer=self.depthwise_initializer,
+        name='depthwise_kernel',
+        regularizer=self.depthwise_regularizer,
+        constraint=self.depthwise_constraint)
+
+    if self.use_bias:
+      self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),
+                                  initializer=self.bias_initializer,
+                                  name='bias',
+                                  regularizer=self.bias_regularizer,
+                                  constraint=self.bias_constraint)
+    else:
+      self.bias = None
+    # Set input spec.
+    self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})
+    self.built = True
+
+    self.opt.set_shape(self.kernel_size + (input_dim, self.depth_multiplier))
+
+
+  def call(self, inputs):
+    depthwise_kernel = self.opt.optimize(self.depthwise_kernel)
+    outputs = backend.depthwise_conv2d(
+        inputs,
+        depthwise_kernel,
+        # self.depthwise_kernel,
+        strides=self.strides,
+        padding=self.padding,
+        dilation_rate=self.dilation_rate,
+        data_format=self.data_format)
+
+    if self.use_bias:
+      outputs = backend.bias_add(
+          outputs,
+          self.bias,
+          data_format=self.data_format)
+
+    if self.activation is not None:
+      return self.activation(outputs)
+
+    return outputs
+
+  # @tf_utils.shape_type_conversion
+  def compute_output_shape(self, input_shape):
+    if self.data_format == 'channels_first':
+      rows = input_shape[2]
+      cols = input_shape[3]
+      out_filters = input_shape[1] * self.depth_multiplier
+    elif self.data_format == 'channels_last':
+      rows = input_shape[1]
+      cols = input_shape[2]
+      out_filters = input_shape[3] * self.depth_multiplier
+
+    rows = conv_utils.conv_output_length(rows, self.kernel_size[0],
+                                         self.padding,
+                                         self.strides[0],
+                                         self.dilation_rate[0])
+    cols = conv_utils.conv_output_length(cols, self.kernel_size[1],
+                                         self.padding,
+                                         self.strides[1],
+                                         self.dilation_rate[1])
+    if self.data_format == 'channels_first':
+      return (input_shape[0], out_filters, rows, cols)
+    elif self.data_format == 'channels_last':
+      return (input_shape[0], rows, cols, out_filters)
+
+  def get_config(self):
+    config = super(DepthwiseConv2D, self).get_config()
+    config.pop('filters')
+    config.pop('kernel_initializer')
+    config.pop('kernel_regularizer')
+    config.pop('kernel_constraint')
+    config['depth_multiplier'] = self.depth_multiplier
+    config['depthwise_initializer'] = initializers.serialize(
+        self.depthwise_initializer)
+    config['depthwise_regularizer'] = regularizers.serialize(
+        self.depthwise_regularizer)
+    config['depthwise_constraint'] = constraints.serialize(
+        self.depthwise_constraint)
+    return config
+
+
+@tf.keras.utils.register_keras_serializable()
 class Conv2DTranspose(Conv2D):
     """Transposed convolution layer (sometimes called Deconvolution).
     The need for transposed convolutions generally arises
     from the desire to use a transformation going in the opposite direction
     of a normal convolution, i.e., from something that has the shape of the
     output of some convolution to something that has the shape of its input
     while maintaining a connectivity pattern that is compatible with
```

## Comparing `DDesignerAPI-0.0.6.0.dist-info/LICENSE` & `DDesignerAPI-0.0.6.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `DDesignerAPI-0.0.6.0.dist-info/METADATA` & `DDesignerAPI-0.0.6.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 Metadata-Version: 2.1
 Name: DDesignerAPI
-Version: 0.0.6.0
+Version: 0.0.6.1
 Summary: Deep-learning Designer: Deep-Learning Training Optimization & Layers API(like Keras)
 Home-page: https://github.com/DPI/DDesigner
 Author: Deeper-I
 Author-email: dean@deeper-i.com
 License: Apache-2.0, BSD3-Clause
 Keywords: xwn,pytorch,tensorflow,keras
+Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3.7
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
-License-File: LICENSE
 
 [DDesigner API] Deep-learning Designer API
 ==========================================
 
 # 1. About
 ## 1.1. DDesignerAPI?
 It is a API for deep-learning learning and inference, and an API for application development using multi-platform
@@ -23,15 +23,15 @@
 ### 1.2.1. Layers and Blocks
 * Accelerator enabled layers and the ability to define special layers that are not defined in Keras and others
 * A function that defines a combination of layers as a block and easily composes a block (ex. CONV + BN + ACT + DROPOUT= ConvBlock)
 
 ### 1.2.2. Optimization for Accelerator Usage (XWN)
 * Optimized function to use accelerator
 <br/><br/><br/>
-  
+
 # 2. Support
 ## 2.1. Platforms
 * Tensorflow 2.6.0
 * PyTorch 1.13.1
 
 ## 2.2. Components of Network 
 ### 2.2.1. Layers
@@ -216,7 +216,9 @@
         >>> import ddesigner_api.numpy.examples.examples_numpy as ex
         >>> ex.main()
         >>> ====== NUMPY Examples======
         >>> 1: XWN Transform
         >>> 2: XWN Transform and Pruning
         >>> q: Quit
         >>> Select Case: ...
+
+
```

## Comparing `DDesignerAPI-0.0.6.0.dist-info/RECORD` & `DDesignerAPI-0.0.6.1.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -9,23 +9,23 @@
 ddesigner_api/pytorch/dpi_nn.py,sha256=hSdcmCHOh5nZ-v6_j7peZr9rUJTUT51NrfPYCrFg8zw,6579
 ddesigner_api/pytorch/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ddesigner_api/pytorch/examples/examples_pytorch.py,sha256=nm5tnil7K4pISxJTuJVsfFeAAQLetCEneVmWc_ohge4,13958
 ddesigner_api/pytorch/xwn/__init__.py,sha256=cXUUsRuw46ruQKpC9NqN_k9p5jbZNfqfC8ytSDqE_RA,1694
 ddesigner_api/pytorch/xwn/torch_nn.py,sha256=S-fcGKmkbSDJDnIkpKCA0pamcBzxWAdrO6qN7SCNYKQ,56563
 ddesigner_api/pytorch/xwn/torch_opt.py,sha256=069ELbkNCJOCbiYxYfzCVci9ZTPfdb0Q9DnFgY1qrPU,6317
 ddesigner_api/tensorflow/__init__.py,sha256=q4RdbPLAQVOiRpf5H4WNGeTqWu8GbeW9gav3RFLev18,873
-ddesigner_api/tensorflow/dpi_blocks.py,sha256=H6tpNCrcRw3Tw6ZWGcGCP_hxafEewl89hZ5bcTSvXhk,20578
+ddesigner_api/tensorflow/dpi_blocks.py,sha256=RKuVtzybMgnJxEHVQRsgwGsSLPtx0wrLlWFX7929Vp4,25752
 ddesigner_api/tensorflow/dpi_layers.py,sha256=ybwVUW3joZ_x-r0jMBKLIJB-WyrgKlAKM_cKZ1z0npw,26909
 ddesigner_api/tensorflow/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ddesigner_api/tensorflow/examples/examples_keras.py,sha256=3icVGij_UymaEYkOwO4TZNRkWCBjLLSg-Khtlus_Fu8,7883
 ddesigner_api/tensorflow/examples/examples_tensorflow.py,sha256=HIwwuTR6WVR2raIAVY9rexO0Ex0iiby_jZ3l14r3jn8,3021
 ddesigner_api/tensorflow/xwn/__init__.py,sha256=rYA_nP5hetn02_TPbxkxX7JeO8HrzfxNJmNVLWQz3fM,841
 ddesigner_api/tensorflow/xwn/base_conv.py,sha256=P1f7kJD_YGDJpQFFHcy4hsTGH1TPOKWu2T8cU9g4Q2w,16764
-ddesigner_api/tensorflow/xwn/keras_layers.py,sha256=IAkheCP9Fh-qHwHlYa4sHcWGkPx7cyMYHWEjtYJEftI,29614
+ddesigner_api/tensorflow/xwn/keras_layers.py,sha256=AahG_qqmZBOD1wBOgljiWudlEshUhoN31_-rqC372-k,39707
 ddesigner_api/tensorflow/xwn/keras_opt.py,sha256=8GCkTe9qU9KAhHOjRTXIgaPlzzImYWaPYzqj4ayoi4o,8393
 ddesigner_api/tensorflow/xwn/tf_nn.py,sha256=oaIXhbau-gtFyndce2dF3xWCDOpNhAwCJNLDkR5b5iU,9240
 ddesigner_api/tensorflow/xwn/tf_opt.py,sha256=P45GaEMNKiSIdscX0VYrr02FLx8cbhYeTpMdGDMFOGo,4167
-DDesignerAPI-0.0.6.0.dist-info/LICENSE,sha256=S2Q1V1ou7fTRCDRl0p78yVcGS0q0K_9BqCyhIdsejec,22114
-DDesignerAPI-0.0.6.0.dist-info/METADATA,sha256=EXn80YR3JT0EStHxWREJFtunBsNNMwaUbsLdc-C1kxo,7892
-DDesignerAPI-0.0.6.0.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-DDesignerAPI-0.0.6.0.dist-info/top_level.txt,sha256=qYDp5VPzyYyterLRCKrHqsvRLXTHSMOd-Xiwy2HJ_Ow,14
-DDesignerAPI-0.0.6.0.dist-info/RECORD,,
+DDesignerAPI-0.0.6.1.dist-info/LICENSE,sha256=S2Q1V1ou7fTRCDRl0p78yVcGS0q0K_9BqCyhIdsejec,22114
+DDesignerAPI-0.0.6.1.dist-info/METADATA,sha256=kA77_SAnPJA0dZc-G3NyERIKNJ8yRoNhwmagPsYwD4c,7888
+DDesignerAPI-0.0.6.1.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+DDesignerAPI-0.0.6.1.dist-info/top_level.txt,sha256=qYDp5VPzyYyterLRCKrHqsvRLXTHSMOd-Xiwy2HJ_Ow,14
+DDesignerAPI-0.0.6.1.dist-info/RECORD,,
```

